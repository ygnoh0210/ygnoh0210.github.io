"use strict";(self.webpackChunkportfolio_3=self.webpackChunkportfolio_3||[]).push([[132],{5132:function(e,t,i){i.r(t),i.d(t,{About:function(){return k},open:function(){return z}});var n=i(8227),a=i(5223),s=i(8735),o=i(3046),r=i(1070),c=i(2504),l=i(3526),d=i(8617),p=i(9439),u=i(2791),h=i(3362),x=i(5763),m=i(7279),g=i(5089),f=i(6053),b=i(184),v=[{id:"1",title:"BIASsist : Bias Assistive Tool",description:"An LLM-based approach to mitigate bias expression",image:"/assets/publication_img/9Publi.png",conference:"CHI '25",link:"https://doi.org/10.1145/3706598.3713531",paper:"BIASsist: Empowering News Readers via Bias Identification, Explanation, and Neutralization",date:"Oct.2024-Aug.2025",tags:["bias","news article","assistive tool","LLM-powered application"],abstract:"Biased news articles can distort readers\u2019 perceptions by presenting information in a way that favors or disfavors a particular point of view. Subtly embedded in the text, these biased news articles can shape our views daily without people even realizing it. To address this issue, we propose BIASsist, an LLM-based approach designed to mitigate bias in news articles. Based on existing research, we defined six types of bias and introduced three assistive components\u2014identification, explanation, and neutralization\u2014to provide a broader range of bias information and enhance readers\u2019 bias-awareness. We conducted a mixed-method study with 36 participants to evaluate the effectiveness of BIASsist. The results show participants\u2019 bias awareness significantly improved and their interest in identifying bias increased. Participants also tended to engage more actively in critically evaluating articles. Based on these findings, we discuss its potential to improve media literacy and critical thinking in today\u2019s information overload era."},{id:"2",title:"Conversational Agent for Dementia",description:"Conversational agents for personalized reminiscence.",image:"/assets/publication_img/7Publi.png",conference:"UbiComp(Workshop) '24",link:"https://doi.org/10.1145/3675094.3678377",paper:"Know Me Inside-Out: Conversational and Quiz-Based System for Reminiscence Therapy for People with Dementia",date:"Sep.2023-Sep.2024",tags:["people with dementia (PwD)","reminiscence therapy","personalized dialog"],abstract:"Dementia, marked by progressive memory decline, threatens patients' emotional well-being and sense of identity. This study explores using reminiscence therapy, which leverages past experiences for cognitive and emotional support, addressing challenges like lack of therapist's personal memorabilia and privacy issues in group sessions. We propose a language model-based interactive system that collects and structures patient memories into context-aware quizzes using named-entity recognition, question-generation, and sentiment analysis. A pilot study with 11 dementia patients aged 60-85 evaluated the system's feasibility and effectiveness. Interface usability challenges were noted, highlighting the need for further development to enhance system usability and validate its effectiveness in larger clinical settings."},{id:"3",title:"Gaze Identification",description:"Authentication using pre-attentive gaze patterns.",image:"/assets/publication_img/8Publi.png",conference:"Scientific Data",date:"Mar.2023-Aug.2024",tags:["gaze-based authentication","pre-attentive processing"],link:"https://doi.org/10.1038/s41597-025-04538-3",paper:"Pre-AttentiveGaze: gaze-based authentication dataset with momentary visual interactions",abstract:"This manuscript presents a Pre-AttentiveGaze dataset. One of the defining characteristics of gaze-based authentication is the necessity for a rapid response. In this study, we constructed a dataset for identifying individuals through eye movements by inducing \u201cpre-attentive processing\u201d in response to a given gaze stimulus in a very short time. A total of 76,840 eye movement samples were collected from 34 participants across five sessions. From the dataset, we extracted the gaze features proposed in previous studies, pre-processed them, and validated the dataset by applying machine learning models. This study demonstrates the efficacy of the dataset and illustrates its potential for use in gaze-based authentication of visual stimuli that elicit pre-attentive processing."},{id:"4",title:"Music for the Deaf",description:"Transforming sound into vibrotactile feedback.",image:"/assets/publication_img/6Publi.png",link:"https://doi.org/10.1145/3613904.3642665",paper:"A Way for Deaf and Hard of Hearing People to Enjoy Music by Exploring and Customizing Cross-modal Music Concepts",conference:"CHI '24",date:"Jun.2021-Dec.2023",tags:["deaf and hard-of-hearing (DHH)","music appreciation","music-sensory substitution system","conceptualization"],abstract:"Deaf and hard of hearing (DHH) people enjoy music and access it using a music-sensory substitution system that delivers sound together with the corresponding visual and tactile feedback. However, it is often challenging for them to comprehend the colorful visuals and strong vibrations that are designed to represent music. We confirmed that it is necessary to conceptualize cross-modal mapping before experiencing music sensory substitution through focus group interviews with 24 DHH people. To improve the music appreciation experience, a cross-modal music conceptualization system was implemented herein, which is a prototype that allows DHH people to explore the visuals and vibrations associated with music to perceive and appreciate. An evaluation with 28 DHH individuals demonstrated the capability of the system to improve subjective music appreciation experience via music-sensory substitution. Eventually, DHH people with negative attitudes toward music became positive in the exploration and customization process with our system."},{id:"5",title:"Conversational Agent in Museum",description:"Designing reenacted CAs to enhance museum experience",image:"/assets/publication_img/2Publi.png",link:"https://doi.org/10.3390/app11167420",paper:"Designing Reenacted Chatbots to Enhance Museum Experience",conference:"Applied Sciences",date:"Jun.2019-Sep.2020",tags:["chatbot","embodiment","historical reenactment","learning style","museum experience"],abstract:"The increased availability of chatbots has drawn attention and interest to the study of what answers they provide and how they provide them. Chatbots have become a common sight in museums but are limited to answering only simple and basic questions. Based on the observed potential of chatbots for history education in museums, we investigate how chatbots impact history education and improve the overall experience according to their appearance and language style. For this, we built three models, designed by factors on embodiment and reflection, and 60 sets of answer\u2013questions, designed for the National Museum of Korea. We conducted a study with a total of 34 participants and carried out a variety of analyses covering individual learning styles, museum experience scales, gaze data, in-depth interviews and observations from researchers. We present various results and lessons regarding the effect of embodiment and reflection on the museum experience. Our findings show how people with different learning styles connect with chatbot models and how visitors\u2019 behavior in the museum changes depending on the chatbot model. Specifically, the chatbot model equipped with embodiment and reflection shows its superiority in enhancing the museum experience, in general."}],y=function(){var e=(0,u.useState)(0),t=(0,p.Z)(e,2),i=t[0],r=t[1],l=(0,u.useState)(10),d=(0,p.Z)(l,2),y=d[0],j=d[1],w=(0,u.useState)(!1),z=(0,p.Z)(w,2),k=z[0],S=(z[1],(0,u.useState)(null)),C=(0,p.Z)(S,2),H=C[0],I=C[1],A=(0,a.qY)(),W=A.isOpen,D=A.onOpen,F=A.onClose,P=(0,u.useRef)(null);(0,u.useEffect)((function(){return k||(P.current=setInterval((function(){j((function(e){return e>=100?(T(),10):e+.4}))}),20)),function(){P.current&&clearInterval(P.current)}}),[i,k]);var T=function(){r((function(e){return(e+1)%v.length})),j(10)};return(0,b.jsxs)(s.xu,{w:"100%",maxW:"800px",mx:"auto",textAlign:"center",children:[(0,b.jsxs)(s.xu,{position:"relative",height:"420px",overflow:"hidden",children:[v.map((function(e,t){var n=t===i,a=t===(i-1+v.length)%v.length,r=t===(i+1)%v.length,c=n||a||r?"block":"none",l=n?1:.9,d=n?2:1,p=n?1:.5,u=a?"-60%":r?"60%":"0";return(0,b.jsx)(s.xu,{onClick:function(){return function(e){I(e),D()}(e)},cursor:"pointer",position:"absolute",top:"0",left:"50%",transform:"translateX(-50%) translateX(".concat(u,") scale(").concat(l,")"),transition:"all 0.5s ease-in-out",zIndex:d,opacity:p,display:c,w:"100%",maxW:"600px",children:(0,b.jsxs)(s.xu,{borderWidth:"1px",borderRadius:"lg",overflow:"hidden",boxShadow:"lg",bg:"white",p:4,children:[(0,b.jsx)(s.xu,{position:"absolute",top:"0",right:"0",p:2,zIndex:3,children:(0,b.jsx)(x.lzP,{color:"black",style:{width:"24px",height:"24px"}})}),(0,b.jsx)(s.M5,{h:"200px",children:(0,b.jsx)(o.Ee,{src:e.image,alt:e.title,maxH:"100%",maxW:"100%",objectFit:"contain"})}),(0,b.jsx)(s.X6,{color:"black",fontSize:"xl",mt:4,children:e.title}),(0,b.jsx)(s.xv,{mt:2,color:"gray.600",children:e.description})]})},e.id)})),(0,b.jsx)(s.xu,{as:"button",onClick:function(){r((function(e){return 0===e?v.length-1:e-1})),j(10)},position:"absolute",left:"0",top:"40%",transform:"translateY(-50%)",zIndex:3,w:"50px",h:"80px",display:"flex",alignItems:"center",justifyContent:"center",borderRadius:"full",_hover:{bg:"gray.100"},children:(0,b.jsx)(f.Ugn,{color:"black",style:{width:"40px",height:"40px"}})}),(0,b.jsx)(s.xu,{as:"button",onClick:T,position:"absolute",right:"0",top:"40%",transform:"translateY(-50%)",zIndex:3,w:"50px",h:"80px",display:"flex",alignItems:"center",justifyContent:"center",borderRadius:"full",_hover:{bg:"gray.100"},children:(0,b.jsx)(f.ULj,{color:"black",style:{width:"40px",height:"40px"}})})]}),(0,b.jsx)(s.Ug,{mt:"-50",spacing:2,justify:"center",children:v.map((function(e,t){return(0,b.jsx)(s.xu,{w:"80px",cursor:"pointer",onClick:function(){return function(e){r(e),j(10)}(t)},children:(0,b.jsx)(m.Ex,{size:"xs",colorScheme:t===i?"blue":"gray",value:t===i?y:t<i?100:0,borderRadius:"full",transition:"all 0.2s"})},t)}))}),(0,b.jsxs)(g.u_,{isOpen:W,onClose:F,isCentered:!0,size:"l",children:[(0,b.jsx)(g.ZA,{}),(0,b.jsxs)(g.hz,{w:{base:"95vw",md:"60vw",lg:"50vw"},maxW:"none",display:"flex",flexDirection:"column",maxH:"90vh",children:[(0,b.jsx)(g.xB,{fontSize:"20",borderBottom:"1px solid",borderColor:"gray.200",_dark:{borderColor:"gray.600"},px:6,py:4,position:"sticky",top:0,bg:(0,n.ff)("gray.50","gray.800"),zIndex:1,children:null===H||void 0===H?void 0:H.paper}),(0,b.jsx)(g.ol,{}),(0,b.jsxs)(g.fe,{px:6,pt:4,pb:2,overflowY:"auto",flex:"1",children:[(0,b.jsx)(s.xv,{fontSize:"16",fontWeight:"700",children:null===H||void 0===H?void 0:H.conference}),(0,b.jsx)(s.xv,{fontSize:"16",fontWeight:"700",color:"gray.500",mb:1,children:null===H||void 0===H?void 0:H.date}),(null===H||void 0===H?void 0:H.tags)&&H.tags.length>0&&(0,b.jsx)(s.xu,{mb:4,children:(0,b.jsx)(h.$,{tags:H.tags})}),(0,b.jsx)(o.Ee,{src:null===H||void 0===H?void 0:H.image,alt:null===H||void 0===H?void 0:H.title,mb:6,maxH:"300px",mx:"auto",objectFit:"contain"}),(0,b.jsx)(s.xv,{fontSize:"md",fontWeight:"bold",color:"gray.700",mb:1,_dark:{color:"gray.100"},children:"abstract"}),(0,b.jsx)(s.xv,{fontSize:"md",color:"gray.800",_dark:{color:"gray.100"},mb:4,children:null===H||void 0===H?void 0:H.abstract})]}),(0,b.jsxs)(g.mz,{px:5,py:4,bg:(0,n.ff)("gray.50","gray.800"),children:[(null===H||void 0===H?void 0:H.link)&&(0,b.jsx)(c.zx,{as:"a",href:H.link,target:"_blank",rel:"noopener noreferrer",variant:"outline",mr:3,px:1,py:0,children:"View Paper"}),(0,b.jsx)(c.zx,{px:3,onClick:F,children:"Close"})]})]})]})]})},j=function(e){var t=e.children,i=e.color,a=(0,n.ff)("".concat(i,".100"),"".concat(i,".900")),o=(0,n.ff)("".concat(i,".800"),"".concat(i,".50"));return(0,b.jsx)(s.xv,{as:"span",px:.5,py:0,bg:a,color:o,fontSize:"14",fontWeight:"semibold",whiteSpace:"nowrap",children:t})},w=function(){var e=(0,n.ff)("gray.700","gray.200"),t=(0,u.useState)(!1),i=(0,p.Z)(t,2),a=i[0],o=i[1],r=[{year:"2025",items:[{date:"Jun",text:(0,b.jsxs)(b.Fragment,{children:[(0,b.jsx)(j,{color:"purple",children:"filed"})," a"," ",(0,b.jsx)(j,{color:"purple",children:"patent application"})," with the Korean Intellectual Property Office"]})},{date:"Apr",text:(0,b.jsxs)(b.Fragment,{children:[(0,b.jsx)(j,{color:"purple",children:"presented"})," our work at"," ",(0,b.jsx)(j,{color:"purple",children:"CHI"})," conference in Yokohama"]})},{date:"Jan",text:(0,b.jsxs)(b.Fragment,{children:["our paper was ",(0,b.jsx)(j,{color:"green",children:"accepted"})," to"," ",(0,b.jsx)(j,{color:"green",children:"CHI"})]})},{date:(0,b.jsx)(b.Fragment,{children:"Jan "}),text:(0,b.jsxs)(b.Fragment,{children:["a paper I co-authored was ",(0,b.jsx)(j,{color:"green",children:"accepted"})," to"," ",(0,b.jsx)(j,{color:"green",children:"Scientific Data"})," ",(0,b.jsx)(s.xu,{mb:"3"})," ",(0,b.jsx)("hr",{})," ",(0,b.jsx)(s.xu,{mb:"3"})]})}]},{year:"2024",items:[{date:"Oct",text:(0,b.jsxs)(b.Fragment,{children:["our paper was ",(0,b.jsx)(j,{color:"green",children:"accepted"})," at ",(0,b.jsx)(j,{color:"green",children:"UbiComp Companion"})]})},{date:"May",text:(0,b.jsxs)(b.Fragment,{children:["joined the ",(0,b.jsx)(j,{color:"purple",children:"CHI"})," conference in Hawaii"]})},{date:"Jan",text:(0,b.jsxs)(b.Fragment,{children:["a paper I co-authored was ",(0,b.jsx)(j,{color:"green",children:"accepted"})," to"," ",(0,b.jsx)(j,{color:"green",children:"CHI"})," ",(0,b.jsx)(s.xu,{mb:"3"})," ",(0,b.jsx)("hr",{})," ",(0,b.jsx)(s.xu,{mb:"3"})]})}]},{year:"2023",items:[{date:"Nov",text:(0,b.jsxs)(b.Fragment,{children:["visited the ",(0,b.jsx)(j,{color:"blue",children:"Toronto Univ"})," and introduced my projects"]})},{date:"Oct",text:(0,b.jsxs)(b.Fragment,{children:["visited the ",(0,b.jsx)(j,{color:"blue",children:"MIT"})," in Boston and met with collaborators"]})},{date:"Apr",text:(0,b.jsxs)(b.Fragment,{children:["attended the ",(0,b.jsx)(j,{color:"purple",children:"CHI"})," conference in Hamberg  ",(0,b.jsx)(s.xu,{mb:"3"})," ",(0,b.jsx)("hr",{})," ",(0,b.jsx)(s.xu,{mb:"3"})]})}]},{year:"2022",items:[{date:"Nov",text:(0,b.jsxs)(b.Fragment,{children:["started my ",(0,b.jsx)(j,{color:"gray",children:"Ph.D journey"})," in Human-Computer Interaction. ",(0,b.jsx)(s.xu,{mb:"3"})," ",(0,b.jsx)("hr",{})," ",(0,b.jsx)(s.xu,{mb:"3"})]})}]},{year:"2019",items:[{date:"Feb",text:(0,b.jsxs)(b.Fragment,{children:["took part in ",(0,b.jsx)(j,{color:"purple",children:"DeveloperWeek"})," held in Oakland ",(0,b.jsx)(s.xu,{mb:"3"})," ",(0,b.jsx)("hr",{})," ",(0,b.jsx)(s.xu,{mb:"3"})]})}]},{year:"2018",items:[{date:"Dec",text:(0,b.jsxs)(b.Fragment,{children:["started ",(0,b.jsx)(j,{color:"blue",children:"Internship"})," in Silicon Valley ",(0,b.jsx)(s.xu,{mb:"3"})," ",(0,b.jsx)("hr",{})," ",(0,b.jsx)(s.xu,{mb:"3"})]})}]}],l=a?r:r.slice(0,3);return(0,b.jsxs)(s.xu,{children:[(0,b.jsx)(s.rj,{templateColumns:"repeat(10, 1fr)",gap:1,children:l.map((function(t,i){return t.items.map((function(i,n){return(0,b.jsxs)(s.xu,{display:"contents",children:[0===n?(0,b.jsx)(s.P4,{colSpan:1,rowSpan:t.items.length,children:(0,b.jsx)(s.xv,{color:e,fontSize:"16",fontWeight:"700",children:t.year})}):null,(0,b.jsx)(s.P4,{colSpan:1,children:(0,b.jsx)(s.xv,{fontSize:"14",fontWeight:"semibold",children:i.date})}),(0,b.jsx)(s.P4,{colSpan:8,children:(0,b.jsx)(s.xv,{fontSize:"14",children:i.text})})]},"".concat(t.year,"-").concat(n))}))}))}),r.length>3&&(0,b.jsx)(s.kC,{justify:"flex-end",children:(0,b.jsx)(c.zx,{size:"sm",variant:"link",fontWeight:500,color:e,onClick:function(){return o(!a)},children:a?"Show less":"Show more"})})]})},z=function(e){return window.open(e,"_blank")},k=function(){var e=(0,l.r0)(l.nl.About),t=((0,n.ff)("gray.700","gray.200"),(0,a.qY)()),i=(t.isOpen,t.onToggle,(0,a.qY)());i.isOpen,i.onToggle;return(0,b.jsxs)(s.xu,{pb:"5",children:[(0,b.jsxs)(s.kC,{pb:"2",pt:"10",gap:{base:6,md:6,lg:12},direction:{base:"column",md:"row"},children:[(0,b.jsx)(s.xu,{mt:"5",flex:"0.2",children:(0,b.jsxs)("picture",{children:[(0,b.jsx)("source",{type:"image/webp",src:l.rH.landing.picture}),(0,b.jsx)("source",{type:"image/jpeg",src:l.rH.landing.jpg}),(0,b.jsx)(o.Ee,{mb:"5",boxSize:"s",borderRadius:"full",src:l.rH.landing.jpg,alt:"face-cover-image"})]})}),(0,b.jsx)(s.xu,{flex:"0.8",children:(0,b.jsxs)(s.xu,{pt:"0",children:[(0,b.jsxs)(s.xv,{pt:"5",fontSize:"18px",fontWeight:"600",children:["Hi, I'm Yeo-Gyeong Noh",(0,b.jsx)(r.u,{hasArrow:!0,label:"Play pronunciation",bg:"gray.300",color:"black",placement:"top-end",children:(0,b.jsx)(c.zx,{size:"m","aria-label":"pronunciation button",as:c.hU,variant:"icon",fontSize:"md",color:"primary.500",icon:(0,b.jsx)(d.w$N,{}),onClick:function(){new Audio(l.rH.common.audioFile).play()}})})]}),(0,b.jsx)(l.VY,{fontSize:"16px",children:e.about})]})})]}),(0,b.jsxs)(s.kC,{pb:"2",pt:"5",gap:{base:6,md:6,lg:12},direction:{base:"column",md:"row"},children:[(0,b.jsxs)(s.xu,{flex:"0.5",children:[(0,b.jsx)(s.xv,{pt:"5",mb:"2",fontSize:"20px",fontWeight:"bold",children:"Updates"}),(0,b.jsx)(w,{})]}),(0,b.jsxs)(s.xu,{flex:"0.5",children:[(0,b.jsx)(s.xv,{pt:"5",mb:"2",fontSize:"20px",fontWeight:"bold",children:"Research Thumbnails"}),(0,b.jsx)(y,{})]})]})]})}},3362:function(e,t,i){i.d(t,{$:function(){return s}});var n=i(8735),a=i(184),s=function(e){var t=e.id,i=e.tags,s=e.size,o=void 0===s?"md":s;return(0,a.jsx)(n.kC,{py:"1",wrap:"wrap",gap:"1",children:i.map((function(e,i){return(0,a.jsx)(n.xu,{"data-aos":"flip-left","data-aos-delay":50*i,children:(0,a.jsx)(n.Ct,{transition:"0.2s ease-in-out",transitionProperty:"primary.50, color",textTransform:"none",color:"g",borderRadius:"md",px:"8px",py:"1px",fontSize:o,fontWeight:"600",children:e})},"".concat(t,"-tag-").concat(e))}))})}}}]);
//# sourceMappingURL=132.e91a8783.chunk.js.map